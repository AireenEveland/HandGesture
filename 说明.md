
### **1. 数据流动基于HTTP协议**

1.  **前端捕获数据**：
    *   `JavaScript` 通过浏览器API (`navigator.mediaDevices.getUserMedia`) 指挥你的**摄像头**，捕获一帧视频画面。
    *   这一帧画面被绘制到一个隐藏的 `<canvas>` 元素上，并被打包成一个**PNG图片文件** (Blob对象)。

2.  **前端发送HTTP请求**：
    *   `JavaScript` 使用 `fetch` API 创建一个 **HTTP POST 请求**。POST请求通常用于向服务器提交数据。
    *   请求的目标地址是 `http://localhost:8001/recognize”。
    *   PNG图片文件被放进请求的“包裹”（`FormData`）里，一起发送出去。

3.  **网络传输**：
    *   这个HTTP请求（带着图片数据）通过你电脑内部的网络（因为是`localhost`）从浏览器（前端）发送到正在 `8001` 端口监听的Uvicorn服务器（后端）。

4.  **后端处理请求**：
    *   **FastAPI** 框架接收到这个请求，看到地址是 `/recognize`，就知道要调用我们写的 `recognize_and_draw` 函数。
    *   它从请求中解包，拿出图片文件，用`OpenCV`解码成图像数据。
    *   `MediaPipe` 库（大厨）对图像进行复杂的计算，识别出手的位置和手势。
    *   `OpenCV` 再次介入，在图像上画出骨架。
    *   后端将处理结果（包含画好骨架的图片和手势信息）打包成一个**JSON对象**。JSON是一种轻量级的数据交换格式，就像后厨把菜品和备注写在一张标准格式的卡片上。

5.  **后端发送HTTP响应**：
    *   FastAPI将这个JSON对象作为 **HTTP 响应** 的“主体”（Response Body）发送回给刚才发起请求的前端。

6.  **前端接收并渲染**：
    *   前端的 `fetch` 函数收到了这个响应，`JavaScript` 解析其中的JSON数据。
    *   它拿出JSON里的 `imageData` (Base64编码的图片)，更新 `<img>` 标签的 `src` 属性，于是你看到了处理后的画面。
    *   它拿出 `handData` (手势信息数组)，更新信息面板里的文字内容。
    *   同时，它计算从发送请求到收到响应的时间差，更新“延迟”显示。

这个过程以每秒约6-7次的频率（`setInterval(sendFrame, 150)`)不断重复，从而形成了你看到的“实时”效果。

### **3. 我们项目的架构模块分解**

我们可以将整个系统分解为以下几个关键模块：

#### **前端 (Client-Side)**

*   **视图层 (View)**
    *   **技术**: `HTML`
    *   **功能**: 负责构建页面的骨架和结构。定义了有哪些元素，比如视频框 `<video>`、图像框 `<img>`、信息面板 `<div>` 等。
*   **表现层 (Presentation)**
    *   **技术**: `CSS`
    *   **功能**: 负责页面的美化和布局，决定了这些元素长什么样、在哪里、多大尺寸、什么颜色。
*   **逻辑层 (Logic)**
    *   **技术**: `JavaScript`
    *   **功能**: 这是前端的“大脑”，负责所有动态行为：
        *   **设备交互**: 调用摄像头。
        *   **事件处理**: 定时器 `setInterval` 周期性地触发数据发送。
        *   **API通信**: 使用 `fetch` 与后端进行数据收发。
        *   **DOM操作**: 接收到后端数据后，动态更新页面上的图像和文字信息。

#### **后端 (Server-Side)**

*   **Web服务层 (Web Service Layer)**
    *   **技术**: `Uvicorn` + `FastAPI`
    *   **功能**:
        *   `Uvicorn` 扮演**Web服务器**的角色，负责监听网络端口（如8001），接收原始的HTTP请求，并将它们传递给应用。
        *   `FastAPI` 是**Web框架**，它解析HTTP请求的细节（比如URL路径、请求体里的数据），并根据我们定义的“路由” (`@app.post("/recognize")`)，将请求分发给正确的处理函数。它还负责将函数的返回结果打包成合法的HTTP响应。
*   **业务逻辑层 (Business Logic Layer)**
    *   **技术**: `Python` (`recognize_digits_1_to_5_definitive` 函数等)
    *   **功能**: 这是后端的“核心大脑”，包含了所有真正的“工作”逻辑。它定义了如何一步步地识别手势：接收图像 -> 翻转 -> 调用模型 -> 判断手指 -> 返回结果。**这是与具体业务（手势识别）最紧密相关的部分**。
*   **计算/视觉处理层 (Computation/Vision Layer)**
    *   **技术**: `MediaPipe`, `OpenCV`, `NumPy`
    *   **功能**: 提供了实现业务逻辑所需的专业工具。
        *   `MediaPipe`：负责最核心、最复杂的AI计算，从像素中找出手的21个关键点。
        *   `OpenCV`：负责图像的读写、翻转、绘制图形和文字等基础图像处理。
        *   `NumPy`：提供了高效处理图像数据（多维数组）的能力。

